{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-processing: Flood Events\n",
    "\n",
    "**Tasks**\n",
    "* Extract all major flood_dates for every country in the provided food crisis dataset.\n",
    "* Filter food crisis data based on the months before/after flooding events identified.\n",
    "* Run time: < 1 minute\n",
    "\n",
    "**WARNING**: There are problems with the Afghanistan data in the original food crisis dataset (i.e. the admin2 codes\n",
    "are actually admin1). This code does not include error handling for that FEWS Country.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import timeit\n",
    "\n",
    "os.getcwd()\n",
    "start = timeit.default_timer()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**1. Read Data**\n",
    "* In CSV format. Shapefiles formats are not recommended due to computational costs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Read Food Security data\n",
    "FS = pd.read_csv('Data/FS_data.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Read Flood Event data\n",
    "FE = pd.read_csv('Data/global_flooding_events.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2. Clean Flooding Event Data**\n",
    "* Needs to be within time frame that is compatible with both the food crisis data (2010-2019) and SARS data\n",
    "(2015-Present)\n",
    "* Data will be cleaned to only include countries from provided food crises dataset (in this case - Burkina Faso,\n",
    "Chad, Mali, Niger)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# CLEAN FE DATA\n",
    "# Remove FE dates before 2010\n",
    "FE.drop(FE.index[FE['year'] == 2000], inplace=True)\n",
    "FE.drop(FE.index[FE['year'] == 2001], inplace=True)\n",
    "FE.drop(FE.index[FE['year'] == 2002], inplace=True)\n",
    "FE.drop(FE.index[FE['year'] == 2003], inplace=True)\n",
    "FE.drop(FE.index[FE['year'] == 2004], inplace=True)\n",
    "FE.drop(FE.index[FE['year'] == 2005], inplace=True)\n",
    "FE.drop(FE.index[FE['year'] == 2006], inplace=True)\n",
    "FE.drop(FE.index[FE['year'] == 2007], inplace=True)\n",
    "FE.drop(FE.index[FE['year'] == 2008], inplace=True)\n",
    "FE.drop(FE.index[FE['year'] == 2009], inplace=True)\n",
    "FE.drop(FE.index[FE['year'] == 2010], inplace=True)\n",
    "FE.drop(FE.index[FE['year'] == 2011], inplace=True)\n",
    "FE.drop(FE.index[FE['year'] == 2012], inplace=True)\n",
    "FE.drop(FE.index[FE['year'] == 2013], inplace=True)\n",
    "FE.drop(FE.index[FE['year'] == 2014], inplace=True)\n",
    "\n",
    "# Remove duplicates\n",
    "FE = FE.drop_duplicates(subset=['country', 'year', 'month'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**3. Create Timestamps**\n",
    "* For both food crises data and flooding event data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Create Timestamps (MONTHLY)\n",
    "# FS\n",
    "FS['date'] = FS['year'].astype(str) + '-' + FS['month'].astype(str)\n",
    "FS['datetime'] = pd.to_datetime(FS['date'])\n",
    "FS = FS.drop(['date'], axis=1)\n",
    "#FE\n",
    "FE['date'] = FE['year'].astype(str) + '-' + FE['month'].astype(str) + '-' +FE['day'].astype(str)\n",
    "FE['datetime'] = pd.to_datetime(FE['date'])\n",
    "FE = FE.drop(['date'], axis=1)\n",
    "FE['datetime_round'] = pd.to_datetime(FE['datetime']).dt.to_period('M').dt.to_timestamp()\n",
    "FE = FE.reset_index()\n",
    "FE = FE.drop(['index'], axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**4. Filter Flooding Event Data**\n",
    "* To only include flooding events for relevant countries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Burkina Faso', 'Chad', 'Mali', 'Niger'}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Flood events for relevant countries (from FS dataset)\n",
    "country_list = set(FS['country'].tolist()) # Extract list of FEWS NET countries\n",
    "FE2 = pd.DataFrame(columns=list(FE.columns))\n",
    "for i in FE.index:\n",
    "    for country in country_list:\n",
    "        if FE['country'][i] == country:\n",
    "            FE2 = FE2.append(FE.loc[i])\n",
    "FE2 = FE2.sort_values(by=['country', 'year', 'month', 'day'])\n",
    "FE2 = FE2.drop(['area', 'exposed'], axis=1)\n",
    "country_list\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**5. Filter Food Crisis Data**\n",
    " * To only include data from before/after each identified flooding event"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Filter FS data to only include data before/after/during each event\n",
    "FS2 = pd.DataFrame(columns=list(FS.columns))\n",
    "FS2['state'] = ''\n",
    "FS2['flood_date'] = ''\n",
    "for event in FE2.index:\n",
    "    for i in FS.index:\n",
    "        if FS['country'][i] == FE2['country'][event]:\n",
    "            FS_date = FS['datetime'][i]\n",
    "            FE_date = FE2['datetime_round'][event]\n",
    "            before = FE_date - pd.DateOffset(months=1)\n",
    "            after = FE_date + pd.DateOffset(months=1)\n",
    "            if FS_date == before:\n",
    "                FS2 = FS2.append(FS.loc[i])\n",
    "                FS2.loc[i,['state']] = 'Before'\n",
    "                FS2.loc[i, ['flood_date']] = FE2['datetime'][event]\n",
    "            elif FS_date == after:\n",
    "                FS2 = FS2.append(FS.loc[i])\n",
    "                FS2.loc[i,['state']] = 'After'\n",
    "                FS2.loc[i, ['flood_date']] = FE2['datetime'][event]\n",
    "            else:\n",
    "                continue\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**6. Clean Up New Data**\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Time:  34.6736503 seconds\n"
     ]
    }
   ],
   "source": [
    "# Clean up Food Crisis Data Before/After\n",
    "FS2 = FS2.reset_index()\n",
    "FS2 = FS2.drop(['index'], axis=1)\n",
    "FS2['datetime'] = FS2['datetime'].astype(str)\n",
    "FS2['flood_date'] = FS2['flood_date'].astype(str)\n",
    "FS2 = FS2[['country', 'admin_name', 'state', 'datetime', 'flood_date', 'fews_ipc', 'ndvi_mean', 'rain_mean',\n",
    "           'et_mean', 'acled_count', 'acled_fatalities', 'p_staple_food', 'area', 'cropland_pct', 'pop',\n",
    "           'ruggedness_mean', 'pasture_pct', 'spacelag', 'timelag1', 'timelag2', 'geometry']]\n",
    "\n",
    "# Clean up Flood Event Data - For GEE\n",
    "FE3 = FS2[['country', 'flood_date', 'datetime', 'state']]\n",
    "FE3 = FE3.drop_duplicates()\n",
    "FE3 = FE3.reset_index()\n",
    "FE3 = FE3.drop(['index'], axis=1)\n",
    "\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Running Time: ', stop - start, 'seconds')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**7. Save Data**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Save data\n",
    "FS2.to_csv('Data/FS_before_after_data.csv', index = False)\n",
    "FE3.to_csv('Data/FE_before_after_dates.csv', index = False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}